
# SET SIMULATION PARAMETERS MATRIX -----------------------------------------

# FOR CLUSTER USE
path = "/home/groups/manishad/SAPH"
setwd(path)
source("helper_SAPH.R")

allPackages = c("here",
                "magrittr",
                "dplyr",
                "data.table",
                "tidyverse",
                "tidyr",
                "metafor",
                "robumeta",
                "testthat",
                "truncdist",
                "gmm",
                "tmvtnorm",
                "doParallel",
                "foreach")


( packagesNeeded = allPackages[ !( allPackages %in% installed.packages()[,"Package"] ) ] )
if( length(packagesNeeded) > 0 ) install.packages(packagesNeeded)

# load all packages
lapply( allPackages,
        require,
        character.only = TRUE)

#**you need to see all "TRUE" printed by this in order for the package to actually be loaded

# set up sim params for cluster

# Note that if you don't include any of these: jeffreys-sd ; jeffreys-var ; mle-sd ; mle-var
#  then you'll need to comment out Optim variables from the analysis.vars in make_agg_data and 
#  also from mutate in there
# I think a similar thing will be true with the Rhats if you omit jeffreys-mcmc?

# ### FULL VERSION ###
scen.params = tidyr::expand_grid(
  # full list (save):
  # rep.methods = "naive ; gold-std ; pcurve ; maon ; 2psm ; jeffreys-mcmc ; jeffreys-sd ; jeffreys-var ; mle-sd ; mle-var ; csm-mle-sd ; 2psm-csm-dataset ; prereg-naive",
  # rep.methods = "naive ; gold-std ; pcurve ; maon ; 2psm ; jeffreys-mcmc ; 2psm-csm-dataset ; csm-mcmc ; prereg-naive",
  rep.methods = "jeffreys-mcmc",

  # args from sim_meta_2
  Nmax = 30,
  Mu = c(0.5),
  t2a = c(0, 0.2^2, 0.3^2, 0.5^2),
  #t2a = 0,
  #t2w = 0,
  t2w = c(0, 0.2^2),
  m = 50,

  #hack = c("favor-best-affirm-wch", "affirm", "affirm2"),
  hack = c("favor-best-affirm-wch"),
  rho = c(0),
  #k.pub.nonaffirm = c(10, 15, 20, 30, 50, 70, 100),
  k.pub.nonaffirm = c(10, 20, 50, 100),
  #k.pub.nonaffirm = c(25),
  prob.hacked = c(0.8),

  true.sei.expr = c("0.02 + rexp(n = 1, rate = 3)"),
  # true.sei.expr = c("0.02 + rexp(n = 1, rate = 3)",
  #                   "rbeta(n = 1, 2, 5)"),

  # Stan control args
  stan.maxtreedepth = 20,
  stan.adapt_delta = 0.98,

  get.CIs = TRUE,
  run.optimx = FALSE )

# ### 2022-4-16: DEBUG NEW PRIOR ###
#
# # with new prior, this scen had only 91% coverage
# scen.params = tidyr::expand_grid(
#   # full list (save):
#   # rep.methods = "naive ; gold-std ; pcurve ; maon ; 2psm ; jeffreys-mcmc ; jeffreys-sd ; jeffreys-var ; mle-sd ; mle-var ; csm-mle-sd ; 2psm-csm-dataset ; prereg-naive",
#   rep.methods = "naive ; jeffreys-mcmc",
#   
#   # args from sim_meta_2
#   Nmax = 30,
#   Mu = c(0.5),
#   t2a = c(0),
#   t2w = c(0),
#   m = 50,
#   
#   hack = c("favor-best-affirm-wch"),
#   rho = c(0),
#   k.pub.nonaffirm = c(25),
#   prob.hacked = c(0.8),
#   
#   true.sei.expr = c("0.1 + rexp(n = 1, rate = 1.5)"), 
#   
#   # Stan control args
#   stan.maxtreedepth = 20,
#   stan.adapt_delta = 0.98,
#   
#   get.CIs = TRUE,
#   run.optimx = FALSE )


### 2022-4-5: ISOLATE SCEN FOR CSM AND SMKH ###

# scen.params = tidyr::expand_grid(
#   # full list (save):
#   # rep.methods = "naive ; gold-std ; pcurve ; maon ; 2psm ; jeffreys-mcmc ; jeffreys-sd ; jeffreys-var ; mle-sd ; mle-var ; csm-mle-sd ; 2psm-csm-dataset ; prereg-naive",
#   rep.methods = "2psm ; jeffreys-mcmc ; 2psm-csm-dataset ; csm-mcmc ; csm-mle-sd ; prereg-naive",
#   
#   # args from sim_meta_2
#   Nmax = 30,
#   Mu = c(0.5),
#   t2a = c(.09),
#   t2w = c(0.04),
#   m = 50,
#   
#   true.sei.expr = c("0.1 + rexp(n = 1, rate = 1.5)"), 
#   hack = c("affirm2"),
#   rho = c(0),
#   k.pub.nonaffirm = c(10, 20, 50, 100),
#   prob.hacked = c(0.8),
#   
#   # Stan control args
#   stan.maxtreedepth = 20,
#   stan.adapt_delta = 0.98,
#   
#   get.CIs = TRUE,
#   #@YOU SHOULD GET OPTIMX FOR THIS RUN
#   run.optimx = FALSE )

# ### 2022-3-24: ISOLATE A FEW SCENS ###
# scen.params = tidyr::expand_grid(
# 
#   rep.methods = "naive ; maon ; 2psm ; jeffreys-mcmc ; csm-mle-sd ; 2psm-csm-dataset",
#   
#   # args from sim_meta_2
#   Nmax = 30,
#   Mu = c(0.5),
#   t2a = c(1.5),
#   t2w = 0.05,
#   m = 50,
#   
#   true.sei.expr = c( #"runif(n = 1, min = 0.1, max = 1)",  # mean=0.55
#     #"runif(n = 1, min = 0.50, max = 0.60)", # mean=0.55 also
#     #"runif(n = 1, min = 0.51, max = 1.5)", # same range as first one, but higher mean
#     #"runif(n = 1, min = 0.1, max = 3)",
#     #"runif(n = 1, min = 1, max = 3)",
#     "0.1 + rexp(n = 1, rate = 1.5)",
#     "rbeta(n = 1, 2, 5)",
#     "0.2 + rbeta(n = 1, 2, 5)" ),
#   hack = c("favor-best-affirm-wch", "affirm", "affirm2"),
#   rho = c(0),
#   k.pub.nonaffirm = c(50),
#   prob.hacked = c(0.5), 
#   
#   # Stan control args
#   stan.maxtreedepth = 20,
#   stan.adapt_delta = 0.98,
#   
#   get.CIs = TRUE,
#   run.optimx = TRUE )

# ### 2022-3-16: CSM, LTMA, RTMA ###
# scen.params = tidyr::expand_grid(
#   #rep.methods = "naive ; gold-std ; maon ; 2psm ; jeffreys-mcmc ; jeffreys-sd ; jeffreys-var ; mle-sd ; mle-var",
#   rep.methods = "naive ; 2psm ; jeffreys-mcmc ; mle-sd ; csm-mle-sd ; ltn-mle-sd",
#   
#   # args from sim_meta_2
#   Nmax = c(30, 1),  
#   Mu = c(0.5),
#   t2a = c(0.05),
#   t2w = 0.05,  
#   m = 50,
#   
#   true.sei.expr = c("rbeta(n = 1, 2, 5)"),  
#   hack = c( "favor-best-affirm-wch", "affirm"),
#   rho = c(0),  
#   k.pub.nonaffirm = c(50),
#   prob.hacked = c(0.8), # 2022-3-7-b: ADDED
#   
#   # Stan control args
#   stan.maxtreedepth = 20,
#   stan.adapt_delta = 0.98,
#   
#   get.CIs = TRUE,
#   run.optimx = FALSE )  



# # OLD - Do I still need these?
# # hold constant the number of UNHACKED studies to 800
# scen.params$k[ scen.params$k.hacked == 800 ] = 800*2
# table(scen.params$k, scen.params$k.hacked)
# 
# # remove nonsense combinations
# # rho > 0 is pointless if there's only 1 draw
# scen.params = scen.params %>% dplyr::filter( !(rho > 0 & Nmax == 1) )

# add scen numbers
start.at = 1
scen.params = scen.params %>% add_column( scen = start.at : ( nrow(scen.params) + (start.at - 1) ),
                                          .before = 1 )


( n.scen = nrow(scen.params) )
# look at it
head( as.data.frame(scen.params) )

# write the csv file of params (to Sherlock)
setwd(path)
write.csv( scen.params, "scen_params.csv", row.names = FALSE )


########################### GENERATE SBATCHES ###########################

# load functions for generating sbatch files
source("helper_SAPH.R")

# number of sbatches to generate (i.e., iterations within each scenario)
# n.reps.per.scen = 1000  
# n.reps.in.doParallel = 200  #@if running optimx, I used 100 here and 5:00:00 below
n.reps.per.scen = 2000
n.reps.in.doParallel = 100
( n.files = ( n.reps.per.scen / n.reps.in.doParallel ) * n.scen )


path = "/home/groups/manishad/SAPH"

scen.name = rep( scen.params$scen, each = ( n.files / n.scen ) )
jobname = paste("job", 1:n.files, sep="_")
outfile = paste("rm_", 1:n.files, ".out", sep="")
errorfile = paste("rm_", 1:n.files, ".err", sep="")
write_path = paste(path, "/sbatch_files/", 1:n.files, ".sbatch", sep="")
runfile_path = paste(path, "/testRunFile.R", sep="")


# 2022-2-27: timing benchmark: with all methods and sim.reps = 1, took 2.5 min
sbatch_params <- data.frame(jobname,
                            outfile,
                            errorfile,
                            jobtime = "05:00:00",  #@when running optimx methods, used sim.reps=100 and 5:00:00 here
                            quality = "normal",
                            node_number = 1,
                            mem_per_node = 64000,
                            mailtype =  "NONE",
                            user_email = "mmathur@stanford.edu",
                            tasks_per_node = 16,
                            cpus_per_task = 1,
                            path_to_r_script = paste(path, "/doParallel_SAPH.R", sep=""),
                            args_to_r_script = paste("--args", jobname, scen.name, sep=" "),
                            write_path,
                            stringsAsFactors = F,
                            server_sbatch_path = NA)

generateSbatch(sbatch_params, runfile_path)

n.files

# run just the first one
# sbatch -p qsu,owners,normal /home/groups/manishad/SAPH/sbatch_files/1.sbatch


# 640
path = "/home/groups/manishad/SAPH"
setwd( paste(path, "/sbatch_files", sep="") )
for (i in 1:1) {
  system( paste("sbatch -p qsu,owners,normal /home/groups/manishad/SAPH/sbatch_files/", i, ".sbatch", sep="") )
}



######## If Running Only Some Jobs To Fill Gaps ########

# run in Sherlock ml load R
path = "/home/groups/manishad/SAPH"
setwd(path)
source("helper_SAPH.R")

missed.nums = sbatch_not_run( "/home/groups/manishad/SAPH/long_results",
                              "/home/groups/manishad/SAPH/long_results",
                              .name.prefix = "long_results",
                              .max.sbatch.num = 13300 )



setwd( paste(path, "/sbatch_files", sep="") )
for (i in missed.nums) {
  system( paste("sbatch -p qsu,owners,normal /home/groups/manishad/SAPH/sbatch_files/", i, ".sbatch", sep="") )
}