


# run this interactively in ml load R or via:
#   sbatch -p qsu,owners,normal /home/groups/manishad/SAPH/job_stitch.sbatch
# scontrol show job 33834701
# look at its out file:
# cd /home/groups/manishad/SAPH
# cd /home/users/mmathur
# less rm_stitch.out

# for non-huge simulations, can often run this script interactively in a higher-memory
#  Sherlock session:
# ml load R/4.1.2
# srun --mem=32G --time=3:00:00 --pty bash
# R


# to be run by stitch.sbatch or manually
# To quickly run this script in high-mem interactive session:
# setwd("/home/groups/manishad/SAPH"); source("stitch_on_sherlock_SAPH.R")

# # load command line arguments
# args = commandArgs(trailingOnly = TRUE)
# start.num = as.numeric( args[1] )  # starting results number to stitch
# stop.num = as.numeric( args[2] )  # stopping results number to stitch



path = "/home/groups/manishad/SAPH"
setwd(path)
source("helper_SAPH.R")
source("analyze_sims_helper_SAPH.R")

# PRELIMINARIES ----------------------------------------------

library(data.table)
library(dplyr)
library(testthat)
# s = stitch_files(.results.singles.path = "/home/groups/manishad/SAPH/sim_results/long",
#                  .results.stitched.write.path = "/home/groups/manishad/SAPH/sim_results/overall_stitched",
#                  .name.prefix = "long_results",
#                  .stitch.file.name="stitched.csv")

.results.singles.path = "/home/groups/manishad/SAPH/long_results"
.results.stitched.write.path = "/home/groups/manishad/SAPH/stitched_results"
.name.prefix = "long_results"
.stitch.file.name="stitched.csv"


# MAKE STITCHED DATA ----------------------------------------------

# get list of all files in folder
all.files = list.files(.results.singles.path, full.names=TRUE)

# we only want the ones whose name includes .name.prefix
keepers = all.files[ grep( .name.prefix, all.files ) ]
length(keepers)

# grab variable names from first file
names = names( read.csv(keepers[1] ) )

# read in and rbind the keepers
tables <- lapply( keepers, function(x) read.csv(x, header= TRUE) )

# sanity check: do all files have the same names?
# if not, could be because some jobs were killed early so didn't get doParallelTime
#  variable added at the end
#  can be verified by looking at out-file for a job without name "doParallelTime"
allNames = lapply( tables, names )
# # find out which jobs had wrong number of names
# lapply( allNames, function(x) all.equal(x, names ) )
# allNames[[1]][ !allNames[[1]] %in% allNames[[111]] ]

# bind_rows works even if datasets have different names
#  will fill in NAs
s <- do.call(bind_rows, tables)

names(s) = names( read.csv(keepers[1], header= TRUE) )

if( is.na(s[1,1]) ) s = s[-1,]  # delete annoying NA row
# write.csv(s, paste(.results.stitched.write.path, .stitch.file.name, sep="/") )

cat("\n\n nrow(s) =", nrow(s))
cat("\n nuni(s$scen.name) =", nuni(s$scen.name) )

# ~ Check for Bad Column Names ---------------------------

# not sure why this is needed - has NA columns at end
names(s)
any(is.na(names(s)))

if ( any(is.na(names(s))) ) {
  NA.names = which( is.na(names(s) ) )
  s = s[ , -NA.names ]
  
}

s = s %>% filter(!is.na(scen.name))

# ~ Write stitched.csv ---------------------------

# setwd(.results.stitched.write.path)
# fwrite(s, .stitch.file.name)
# 
# # also make a zipped version
# string = paste("zip -m stitched.zip", .stitch.file.name)
# system(string)


# ~ Optional: Quick Summary and Look for Failed Iterates ---------------------------

t = s %>% group_by(scen.name, k.pub.nonaffirm, Mu, t2a, t2w, method) %>%
  filter( grepl("jeffreys-mcmc", method) ) %>%
  summarise( reps = n(),
             MhatMn = meanNA(Mhat),
             MhatCover = meanNA(MLo < Mu & MHi > Mu),
             MhatWidth = meanNA(MHi - MLo),
             MLo = meanNA(MLo),
             MHi = meanNA(MHi),
             Shat = meanNA(Shat),
             MhatNA = mean(is.na(Mhat)),
             MhatRhatGt1.05 = mean(MhatRhat>1.05),
  MhatRhatGt1.02 = mean(MhatRhat>1.02)) %>%
  #filter(reps > 1000) %>%
    mutate_if(is.numeric, function(x) round(x,2))

as.data.frame(t)


# iterates with acceptable Rhat

t = s %>% group_by(scen.name, k.pub.nonaffirm, Mu, t2a, t2w, method) %>%
  filter( grepl("jeffreys-mcmc", method) &
            MhatRhat < 1.02) %>%
  summarise( reps = n(),
             MhatMn = meanNA(Mhat),
             MhatCover = meanNA(MLo < Mu & MHi > Mu),
             MhatWidth = meanNA(MHi - MLo),
             MLo = meanNA(MLo),
             MHi = meanNA(MHi),
             Shat = meanNA(Shat),
             MhatNA = mean(is.na(Mhat)) ) %>%
  #filter(reps > 1000) %>%
  mutate_if(is.numeric, function(x) round(x,2))


as.data.frame(t)


# MAKE AGG DATA ----------------------------------------------

path = "/home/groups/manishad/SAPH"
setwd(path)
source("helper_SAPH.R")
source("analyze_sims_helper_SAPH.R")

# if this says "problem with column OptimConverged", 
#  you just need to comment out the optim columns in make_agg_data
#  because you didn't run those methods
agg = make_agg_data(s)

setwd(.results.stitched.write.path)
fwrite(agg, "agg.csv")

cat("\n\n nrow(agg) =", nrow(agg))
cat("\n nuni(agg$scen.name) =", nuni(agg$scen.name) )

# look again at failures
t = agg %>% group_by(k.pub.nonaffirm, method) %>%
  summarise( mean(MhatEstFail),
             mean(MhatCIFail),
             mean(MhatTestReject)
             #meanNA(OptimxNAgreeOfConvergersMhatWinner)
             )
as.data.frame(t)


# errors of 2PSM when it fails
table( s$overall.error[ s$method == "2psm" & is.na(s$Mhat) ] )



##### Move to Local #####

# # stitched and agg -> local directory
# scp mmathur@login.sherlock.stanford.edu:/home/groups/manishad/SAPH/stitched_results/* /Users/mmathur/Dropbox/Personal\ computer/Independent\ studies/2021/Sensitivity\ analysis\ for\ p-hacking\ \(SAPH\)/Linked\ to\ OSF\ \(SAPH\)/Sherlock\ simulation\ results/Pilot\ simulations

# LOOK FOR MISSED JOBS ----------------------------------------------

# path = "/home/groups/manishad/SAPH"
# setwd(path)
# source("helper_SAPH.R")
# source("analyze_sims_helper_SAPH.R")
# 
# # look for missed jobs
# missed.nums = sbatch_not_run( "/home/groups/manishad/SAPH/long_results",
#                               "/home/groups/manishad/SAPH/long_results",
#                               .name.prefix = "long",
#                               .max.sbatch.num = 2400)
# 
# setwd( paste(path, "/sbatch_files", sep="") )
# for (i in missed.nums) {
#   system( paste("sbatch -p qsu,owners,normal /home/groups/manishad/SAPH/sbatch_files/", i, ".sbatch", sep="") )
# }

